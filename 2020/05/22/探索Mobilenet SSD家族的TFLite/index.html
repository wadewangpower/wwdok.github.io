<!DOCTYPE html>


<html lang="ch">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    探索Mobilenet SSD家族的TFLite |  Hello World
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/planets.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-172408389-1', 'auto');
ga('send', 'pageview');

</script>



  
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?da92a6672e51fa2d1c3bacf2dba555c6";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-探索Mobilenet SSD家族的TFLite"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  探索Mobilenet SSD家族的TFLite
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/05/22/%E6%8E%A2%E7%B4%A2Mobilenet%20SSD%E5%AE%B6%E6%97%8F%E7%9A%84TFLite/" class="article-date">
  <time datetime="2020-05-22T14:08:20.000Z" itemprop="datePublished">2020-05-22</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/CV/">CV</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">4k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">20 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本篇文章将介绍如何使用脚本将pb格式的预训练模型转换为tflite格式的模型，并使用脚本测试这个生成的tflite的检测效果，以便在部署到移动端之前可以知道这个生成的模型性能如何。您也可以在<a target="_blank" rel="noopener" href="https://colab.research.google.com/gist/jvishnuvardhan/321551f11317d0789027fab2f63186ff/ssd_mobilenet_quantized_model_tflite_converter.ipynb#scrollTo=6EMJAeVrs1pO">gist</a>上快速浏览体验本文的代码。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统：Windows 10</p>
<p>tensorflow 版本：1.15（2.0，2.1也可以，2.2不行,因为它的API没有tf.compat.v1）</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol>
<li><p>从<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">Tensorflow detection model zoo</a>下载<a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz">ssd_mobilenet_v2_quantized_coco</a>这个压缩包，解压之后里面能看到一个<strong>tflite_graph.pb</strong>,这个就是接下来我们要转换的pb格式模型。</p>
</li>
<li><p>将pb格式模型转换成tflite格式模型的脚本如下：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TFLiteConverter_uint8.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line"></span><br><span class="line">graph_def_file = <span class="string">&quot;E:/Tensorflow_detection_model_zoo/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/tflite_graph.pb&quot;</span></span><br><span class="line">input_arrays=[<span class="string">&quot;normalized_input_image_tensor&quot;</span>]</span><br><span class="line">output_arrays=[<span class="string">&#x27;TFLite_Detection_PostProcess&#x27;</span>, <span class="string">&#x27;TFLite_Detection_PostProcess:1&#x27;</span>, <span class="string">&#x27;TFLite_Detection_PostProcess:2&#x27;</span>, <span class="string">&#x27;TFLite_Detection_PostProcess:3&#x27;</span>]</span><br><span class="line">input_shape=&#123;<span class="string">&quot;normalized_input_image_tensor&quot;</span>: [<span class="number">1</span>, <span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>]&#125;</span><br><span class="line"><span class="comment"># 转换模型前请先确认好这个pb模型是否已经量化过了</span></span><br><span class="line">pb_model_has_quantitized = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)</span><br><span class="line">converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]</span><br><span class="line">converter.allow_custom_ops = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">bool</span>(pb_model_has_quantitized) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">    <span class="comment"># 如果pb模型还没有量化过，则使用以下代码。不过测试结果证明，post_training_quantize的精度非常地差</span></span><br><span class="line">    converter.post_training_quantize = <span class="literal">True</span>  <span class="comment"># 如果没有pb模型还没量化过，才使用这句代码</span></span><br><span class="line">    <span class="comment"># 但用这句代码后会报出一个警告：UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.</span></span><br><span class="line">    converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]  <span class="comment"># 这句代码跟上面那句代码选一个就行，最终生成的模型都一样</span></span><br><span class="line">    converter.inference_type = tf.compat.v1.lite.constants.FLOAT  <span class="comment"># `optimizations` require that `inference_type` is set to float.</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 如果pb模型已经量化过了，如ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03，就只使用下面一句代码就够了</span></span><br><span class="line">    converter.inference_type = tf.compat.v1.lite.constants.QUANTIZED_UINT8</span><br><span class="line"></span><br><span class="line">input_arrays = converter.get_input_arrays()</span><br><span class="line">converter.quantized_input_stats = &#123;input_arrays[<span class="number">0</span>]: (<span class="number">128.0</span>, <span class="number">128.0</span>)&#125;  <span class="comment"># mean, std_dev</span></span><br><span class="line">tflite_uint8_model = converter.convert()</span><br><span class="line"><span class="built_in">open</span>(<span class="string">&quot;uint8_model_converted_from_&quot;</span>+os.path.basename(os.path.dirname(graph_def_file))+<span class="string">&quot;.tflite&quot;</span>, <span class="string">&quot;wb&quot;</span>).write(tflite_uint8_model)</span><br></pre></td></tr></table></figure>
<ol>
<li>测试生成的uint8_model_converted_from_ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tflite的检测效果，使用如下脚本：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test_TFLite_Model_With_Image_Folder.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line"><span class="comment"># Load TFLite model and allocate tensors.</span></span><br><span class="line">interpreter = tf.lite.Interpreter(model_path=<span class="string">&quot;uint8_model_converted_from_ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tflite&quot;</span>)</span><br><span class="line">interpreter.allocate_tensors()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get input and output tensors.</span></span><br><span class="line">input_details = interpreter.get_input_details()</span><br><span class="line">output_details = interpreter.get_output_details()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;input_details : &quot;</span>, input_details)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;output_details : &quot;</span>, output_details)</span><br><span class="line"><span class="comment"># 错误的输出结果：&#x27;TFLite_Detection_PostProcess&#x27;的&#x27;shape&#x27;: array是([ 1, 0,  4])</span></span><br><span class="line"><span class="comment"># 官方模型的输出结果：</span></span><br><span class="line"><span class="comment"># [&#123;&#x27;name&#x27;: &#x27;normalized_input_image_tensor&#x27;, &#x27;index&#x27;: 175, &#x27;shape&#x27;: array([  1, 300, 300,   3]), &#x27;dtype&#x27;: &lt;class &#x27;numpy.uint8&#x27;&gt;, &#x27;quantization&#x27;: (0.0078125, 128)&#125;]</span></span><br><span class="line"><span class="comment"># [&#123;&#x27;name&#x27;: &#x27;TFLite_Detection_PostProcess&#x27;, &#x27;index&#x27;: 167, &#x27;shape&#x27;: array([ 1, 10,  4]), &#x27;dtype&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;quantization&#x27;: (0.0, 0)&#125;,</span></span><br><span class="line"><span class="comment">#  &#123;&#x27;name&#x27;: &#x27;TFLite_Detection_PostProcess:1&#x27;, &#x27;index&#x27;: 168, &#x27;shape&#x27;: array([ 1, 10]), &#x27;dtype&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;quantization&#x27;: (0.0, 0)&#125;,</span></span><br><span class="line"><span class="comment">#  &#123;&#x27;name&#x27;: &#x27;TFLite_Detection_PostProcess:2&#x27;, &#x27;index&#x27;: 169, &#x27;shape&#x27;: array([ 1, 10]), &#x27;dtype&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;quantization&#x27;: (0.0, 0)&#125;,</span></span><br><span class="line"><span class="comment">#  &#123;&#x27;name&#x27;: &#x27;TFLite_Detection_PostProcess:3&#x27;, &#x27;index&#x27;: 170, &#x27;shape&#x27;: array([1]), &#x27;dtype&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;quantization&#x27;: (0.0, 0)&#125;]</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Test model on images in folder</span></span><br><span class="line">test_images_dir = <span class="string">&#x27;test_images/&#x27;</span></span><br><span class="line">test_images_list = os.listdir(test_images_dir)</span><br><span class="line"><span class="comment"># print(test_images_list)</span></span><br><span class="line">class_names = [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;motorcycle&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>,<span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;traffic light&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;fire hydrant &#x27;</span>, <span class="string">&#x27;stop sign&#x27;</span>, <span class="string">&#x27;parking meter&#x27;</span>, <span class="string">&#x27;bench&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>,<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>, <span class="string">&#x27;backpack&#x27;</span>, <span class="string">&#x27;umbrella&#x27;</span>, <span class="string">&#x27;handbag&#x27;</span>, <span class="string">&#x27;tie&#x27;</span>,<span class="string">&#x27;suitcase&#x27;</span>, <span class="string">&#x27;frisbee&#x27;</span>, <span class="string">&#x27;skis&#x27;</span>, <span class="string">&#x27;snowboard&#x27;</span>, <span class="string">&#x27;sports ball&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;kite&#x27;</span>, <span class="string">&#x27;baseball bat&#x27;</span>, <span class="string">&#x27;baseball glove&#x27;</span>, <span class="string">&#x27;skateboard&#x27;</span>, <span class="string">&#x27;surfboard&#x27;</span>, <span class="string">&#x27;tennis racket&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;wine glass&#x27;</span>, <span class="string">&#x27; cup&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;fork&#x27;</span>, <span class="string">&#x27;knife&#x27;</span>, <span class="string">&#x27;spoon&#x27;</span>, <span class="string">&#x27;bowl&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;sandwich&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;broccoli&#x27;</span>, <span class="string">&#x27;carrot&#x27;</span>, <span class="string">&#x27;hot dog&#x27;</span>, <span class="string">&#x27;pizza&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;donut&#x27;</span>, <span class="string">&#x27;cake&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;couch&#x27;</span>, <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;dining table&#x27;</span>, <span class="string">&#x27;toilet&#x27;</span>, <span class="string">&#x27;tv&#x27;</span>, <span class="string">&#x27;laptop&#x27;</span>, <span class="string">&#x27;mouse&#x27;</span>, <span class="string">&#x27;remote&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;keyboard&#x27;</span>, <span class="string">&#x27; cell phone&#x27;</span>, <span class="string">&#x27;microwave&#x27;</span>, <span class="string">&#x27;oven&#x27;</span>, <span class="string">&#x27;toaster&#x27;</span>, <span class="string">&#x27;sink&#x27;</span>, <span class="string">&#x27;refrigerator&#x27;</span>, <span class="string">&#x27;book&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;vase&#x27;</span>, <span class="string">&#x27;scissors&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;teddy bear&#x27;</span>, <span class="string">&#x27;hair drier&#x27;</span>, <span class="string">&#x27;toothbrush&#x27;</span>]</span><br><span class="line"></span><br><span class="line">total_interpreter_time = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> test_image <span class="keyword">in</span> test_images_list:</span><br><span class="line">    <span class="comment"># print(test_image)</span></span><br><span class="line">    input_shape = input_details[<span class="number">0</span>][<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line">    image = cv.imread(test_images_dir+test_image)</span><br><span class="line">    <span class="comment"># print(image)</span></span><br><span class="line">    <span class="comment"># print(image.shape)</span></span><br><span class="line">    resize_img = cv.resize(image, (<span class="number">300</span>, <span class="number">300</span>), interpolation=cv.INTER_CUBIC)</span><br><span class="line">    reshape_image = resize_img.reshape(<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># print(reshape_image)</span></span><br><span class="line">    <span class="comment"># print(reshape_image.shape)  # 输出应该是(300, 300, 3)</span></span><br><span class="line">    image_np_expanded = np.expand_dims(reshape_image, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># print(image_np_expanded.shape)  # 输出应该是(1, 300, 300, 3)</span></span><br><span class="line">    image_np_expanded = image_np_expanded.astype(<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># float32</span></span><br><span class="line">    <span class="comment"># print(image_np_expanded)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tflite模型开始正式工作</span></span><br><span class="line">    model_interpreter_start_time = time.time()</span><br><span class="line">    interpreter.set_tensor(input_details[<span class="number">0</span>][<span class="string">&#x27;index&#x27;</span>], image_np_expanded)  <span class="comment"># 当输入数据类型与模型的期望类型不一致时，就会出现“Cannot set tensor: Got tensor of type 1（float32） but expected type 3（uint8） for input 175 ”</span></span><br><span class="line">    interpreter.invoke()</span><br><span class="line">    <span class="comment"># print(output_details[0][&#x27;index&#x27;])  # 输出是167</span></span><br><span class="line">    <span class="comment"># print(output_details[1][&#x27;index&#x27;])  # 输出是168，后面两个以此类推</span></span><br><span class="line">    output_data = interpreter.get_tensor(output_details[<span class="number">0</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data)  # 输出10个目标的位置信息</span></span><br><span class="line">    output_data_1 = interpreter.get_tensor(output_details[<span class="number">1</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_1)  # 输出10个目标的类别id</span></span><br><span class="line">    output_data_2 = interpreter.get_tensor(output_details[<span class="number">2</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_2)  # 输出10个目标的置信度（从高到低）</span></span><br><span class="line">    output_data_3 = interpreter.get_tensor(output_details[<span class="number">3</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_3)  # 输出检测出来的目标个数</span></span><br><span class="line"></span><br><span class="line">    each_interpreter_time = time.time() - model_interpreter_start_time</span><br><span class="line"></span><br><span class="line">    <span class="comment"># max_pointer = output_data.reshape(300, 300, 2).argmax(axis=2)  # Returns the indices of the maximum values along an axis.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(output_data[0][0][0])</span></span><br><span class="line">    <span class="comment"># print(output_data[0][0][1])</span></span><br><span class="line">    <span class="comment"># print(output_data[0][0][2])</span></span><br><span class="line">    <span class="comment"># print(output_data[0][0][3])</span></span><br><span class="line">    <span class="comment"># 输出坐标：（y方向系数，x方向系数，y方向系数，x方向系数），这个系数是乘以原图像的分辨率，不是乘以resize后的300</span></span><br><span class="line">    <span class="comment"># 坐上顶点：（x方向坐标，y方向坐标）</span></span><br><span class="line">    original_image_height, original_image_width, _ = image.shape</span><br><span class="line">    thickness = original_image_height//<span class="number">300</span>  <span class="comment"># 为了适配不同分辨率的图片，动态调整线框厚度和字体缩放比例</span></span><br><span class="line">    fontsize = original_image_height/<span class="number">1000</span></span><br><span class="line">    <span class="comment"># print(test_image + &#x27; width ： &#x27; + str(original_image_width))</span></span><br><span class="line">    <span class="built_in">print</span>(test_image + <span class="string">&#x27; height ： &#x27;</span> + <span class="built_in">str</span>(original_image_height))</span><br><span class="line">    <span class="built_in">print</span>(thickness)</span><br><span class="line">    <span class="built_in">print</span>(fontsize)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output_data_1[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(class_names[int(output_data_1[0][i])])</span></span><br><span class="line">        confidence_threshold = output_data_2[<span class="number">0</span>][i]</span><br><span class="line">        <span class="keyword">if</span> confidence_threshold &gt; <span class="number">0.3</span>:</span><br><span class="line">            <span class="comment"># 只绘制概率大于阈值的矩形框</span></span><br><span class="line">            label = <span class="string">&quot;&#123;&#125;: &#123;:.2f&#125;% &quot;</span>.<span class="built_in">format</span>(class_names[<span class="built_in">int</span>(output_data_1[<span class="number">0</span>][i])], output_data_2[<span class="number">0</span>][i] * <span class="number">100</span>)  <span class="comment"># label包含类别名称、置信度、单张图片推理时间</span></span><br><span class="line">            label2 = <span class="string">&quot;inference time : &#123;:.3f&#125;s&quot;</span> .<span class="built_in">format</span>(each_interpreter_time)</span><br><span class="line">            <span class="comment"># 注意output_data第一个和第二个[]里都是0，然后第三个[]不是按0到3的顺序</span></span><br><span class="line">            left_up_corner = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">1</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">0</span>]*original_image_height))</span><br><span class="line">            left_up_corner_higher = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">1</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">0</span>]*original_image_height)-<span class="number">15</span>)</span><br><span class="line">            right_down_corner = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">3</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">2</span>]*original_image_height))</span><br><span class="line">            cv.rectangle(image, left_up_corner_higher, right_down_corner, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), thickness)</span><br><span class="line">            <span class="comment"># cv.rectangle()里的第2个第3个参数代表的是 左上角点的(x,y)，右下角点的(x,y)，不同于Rect rect(x, y, w, h);//左上坐标（x,y）和矩形的长(w)宽(h)</span></span><br><span class="line">            cv.putText(image, label, left_up_corner_higher, cv.FONT_HERSHEY_DUPLEX, fontsize, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=thickness)</span><br><span class="line">            cv.putText(image, label2, (<span class="number">30</span>, <span class="number">30</span>), cv.FONT_HERSHEY_DUPLEX, fontsize, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=thickness)</span><br><span class="line">    cv.namedWindow(<span class="string">&#x27;detect_result&#x27;</span>, cv.WINDOW_NORMAL)</span><br><span class="line">    cv.resizeWindow(<span class="string">&#x27;detect_result&#x27;</span>, <span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line">    cv.imshow(<span class="string">&quot;detect_result&quot;</span>, image)</span><br><span class="line">    key = cv.waitKey(<span class="number">2000</span>) &amp; <span class="number">0xFF</span>  <span class="comment"># waitKey(delay)里的参数代表延时多少毫秒后刷新窗口画面，delay=0则代表无限延时，=2000代表检测结果每隔2秒轮播</span></span><br><span class="line">    <span class="keyword">if</span> key == <span class="built_in">ord</span>(<span class="string">&quot;q&quot;</span>):  <span class="comment"># 按Q键退出程序</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> key == <span class="number">32</span>:  <span class="comment"># 空格键的ASCII码是32</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;暂停&quot;</span>)</span><br><span class="line">        cv.waitKey(<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;继续&quot;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol>
<li>查看检测结果</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>ssd_mobilenet_v2_quantized</th>
<th>对标模型detect.tflite</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1gMl9.png" alt="t1gMl9.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t12k1H.png" alt="t12k1H.png"></td>
</tr>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1glO1.png" alt="t1glO1.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t12ZnI.png" alt="t12ZnI.png"></td>
</tr>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1cfZ6.png" alt="t1cfZ6.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t1g6k8.png" alt="t1g6k8.png"></td>
</tr>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1gSJg.png" alt="t1gSJg.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t1gLp4.png" alt="t1gLp4.png"></td>
</tr>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1gFLq.png" alt="t1gFLq.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t12S76.png" alt="t12S76.png"></td>
</tr>
<tr>
<td><img src="https://s1.ax1x.com/2020/05/31/t1g0OI.png" alt="t1g0OI.png"></td>
<td><img src="https://s1.ax1x.com/2020/05/31/t12uAf.png" alt="t12uAf.png"></td>
</tr>
</tbody>
</table>
</div>
<p>看上去v2的效果有好一点点，不过这是用更长的推理时间换来的。</p>
<p><strong>视频对比（@小米8SE）：</strong></p>
<iframe width="720" height="480" src="//player.bilibili.com/player.html?aid=968315121&bvid=BV1gp4y1X7Fg&cid=195785533&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>后来我才发现我所对标的detect.tflite不论是从图结构、卷积核大小和个数都更像是<a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync_2018_07_18.tar.gz">ssd_mobilenet_v1_0.75_depth_quantized_coco ☆</a>，但是用<a target="_blank" rel="noopener" href="https://www.lutzroeder.com/ai/netron/">netron</a>仔细查看后发现它们在custom部分的值有些不一样：</p>
<p><img src="https://s1.ax1x.com/2020/05/31/t1G1l4.png" alt="t1G1l4.png"><br>我还发现ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18和ssd_mobilenet_v1_0.75_depth_quantized_coco ☆虽然都是ssd_mobilenet_v1，但转换出来的tflite模型差别还不小，比如正常深度版的图上还能看出relu6层，而0.75深度版的和detect.tflite一样，都没有relu6层。为什么少了relu6层让我很迷惑。我在网上找了两篇论文（其实是同一个东西）研究：《A Quantization-Friendly<br>Separable Convolution for MobileNets》[<a target="_blank" rel="noopener" href="https://www.emc2-ai.org/assets/docs/asplos-18/paper4-presentation.pdf">1</a>][<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.08607.pdf">2</a>]</p>
<p>下面我用<a target="_blank" rel="noopener" href="https://www.lutzroeder.com/ai/netron/">netron</a>展示一下3个模型的部分结构差别：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>ssd_mobilenet_v2_quantized</td>
<td><img src="https://s1.ax1x.com/2020/05/27/tEi2p6.png" alt="tEi2p6.png"></td>
</tr>
<tr>
<td>detect.tflite</td>
<td><img src="https://s1.ax1x.com/2020/05/27/tEiJkn.png" alt="tEiJkn.png"></td>
</tr>
<tr>
<td>ssd_mobilenet_v1_quantized</td>
<td><img src="https://s1.ax1x.com/2020/05/27/tEid6U.png" alt="tEid6U.png"></td>
</tr>
</tbody>
</table>
</div>
<p>另外，为了动态连续地查看模型地检测效果，我还写了个对视频测试地脚本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test_TFLite_Model_With_Video.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br><span class="line"></span><br><span class="line">Model_Path = <span class="string">&quot;C:/MachineLearning/CV/uint8_dequantized_model_converted_from_exported_model.tflite&quot;</span></span><br><span class="line">Video_path = <span class="string">&quot;C:/MachineLearning/CV/Object_Tracking/video2.mp4&quot;</span></span><br><span class="line"></span><br><span class="line">interpreter = tf.lite.Interpreter(model_path=Model_Path)</span><br><span class="line">interpreter.allocate_tensors()</span><br><span class="line"><span class="comment"># Get input and output tensors.</span></span><br><span class="line">input_details = interpreter.get_input_details()</span><br><span class="line">output_details = interpreter.get_output_details()</span><br><span class="line"><span class="comment"># print(&quot;input_details : &quot;, input_details)</span></span><br><span class="line"><span class="comment"># print(&quot;output_details : &quot;, output_details)</span></span><br><span class="line"></span><br><span class="line">class_names = [<span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;motorcycle&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>,<span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;traffic light&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;fire hydrant &#x27;</span>, <span class="string">&#x27;stop sign&#x27;</span>, <span class="string">&#x27;parking meter&#x27;</span>, <span class="string">&#x27;bench&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>, <span class="string">&#x27;backpack&#x27;</span>, <span class="string">&#x27;umbrella&#x27;</span>, <span class="string">&#x27;handbag&#x27;</span>, <span class="string">&#x27;tie&#x27;</span>, <span class="string">&#x27;suitcase&#x27;</span>, <span class="string">&#x27;frisbee&#x27;</span>, <span class="string">&#x27;skis&#x27;</span>, <span class="string">&#x27;snowboard&#x27;</span>, <span class="string">&#x27;sports ball&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;kite&#x27;</span>, <span class="string">&#x27;baseball bat&#x27;</span>, <span class="string">&#x27;baseball glove&#x27;</span>, <span class="string">&#x27;skateboard&#x27;</span>, <span class="string">&#x27;surfboard&#x27;</span>, <span class="string">&#x27;tennis racket&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;wine glass&#x27;</span>, <span class="string">&#x27; cup&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;fork&#x27;</span>, <span class="string">&#x27;knife&#x27;</span>, <span class="string">&#x27;spoon&#x27;</span>, <span class="string">&#x27;bowl&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;sandwich&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;broccoli&#x27;</span>, <span class="string">&#x27;carrot&#x27;</span>, <span class="string">&#x27;hot dog&#x27;</span>, <span class="string">&#x27;pizza&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;donut&#x27;</span>, <span class="string">&#x27;cake&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;couch&#x27;</span>, <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;dining table&#x27;</span>, <span class="string">&#x27;toilet&#x27;</span>, <span class="string">&#x27;tv&#x27;</span>, <span class="string">&#x27;laptop&#x27;</span>, <span class="string">&#x27;mouse&#x27;</span>, <span class="string">&#x27;remote&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;keyboard&#x27;</span>, <span class="string">&#x27; cell phone&#x27;</span>, <span class="string">&#x27;microwave&#x27;</span>, <span class="string">&#x27;oven&#x27;</span>, <span class="string">&#x27;toaster&#x27;</span>, <span class="string">&#x27;sink&#x27;</span>, <span class="string">&#x27;refrigerator&#x27;</span>, <span class="string">&#x27;book&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;vase&#x27;</span>, <span class="string">&#x27;scissors&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;teddy bear&#x27;</span>, <span class="string">&#x27;hair drier&#x27;</span>, <span class="string">&#x27;toothbrush&#x27;</span>]</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(Video_path)</span><br><span class="line">ok, frame_image = cap.read()</span><br><span class="line">original_image_height, original_image_width, _ = frame_image.shape</span><br><span class="line"><span class="comment"># print(&#x27; 帧宽度 ： &#x27; + str(original_image_width))</span></span><br><span class="line"><span class="comment"># print(&#x27; 帧高度 ： &#x27; + str(original_image_height))</span></span><br><span class="line">thickness = original_image_height // <span class="number">500</span>  <span class="comment"># 为了适配不同分辨率的图片，动态调整线框厚度和字体缩放比例</span></span><br><span class="line">fontsize = original_image_height / <span class="number">1500</span></span><br><span class="line"><span class="built_in">print</span>(thickness)</span><br><span class="line"><span class="built_in">print</span>(fontsize)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ok, frame_image = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ok:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    model_interpreter_start_time = time.time()</span><br><span class="line">    resize_img = cv2.resize(frame_image, (<span class="number">300</span>, <span class="number">300</span>), interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    reshape_image = resize_img.reshape(<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># print(reshape_image)</span></span><br><span class="line">    <span class="comment"># print(reshape_image.shape)  # 输出是(300, 300, 3)</span></span><br><span class="line">    image_np_expanded = np.expand_dims(reshape_image, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># print(image_np_expanded.shape)  # 输出是(1, 300, 300, 3)</span></span><br><span class="line">    image_np_expanded = image_np_expanded.astype(<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># float32</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test model</span></span><br><span class="line">    interpreter.set_tensor(input_details[<span class="number">0</span>][<span class="string">&#x27;index&#x27;</span>], image_np_expanded)  <span class="comment"># 当输入数据类型与模型的期望类型不一致时，就会出现“Cannot set tensor: Got tensor of type 1（float32） but expected type 3（uint8） for input 175 ”</span></span><br><span class="line">    interpreter.invoke()</span><br><span class="line">    <span class="comment"># print(output_details[0][&#x27;index&#x27;])  # 输出是167</span></span><br><span class="line">    <span class="comment"># print(output_details[1][&#x27;index&#x27;])  # 输出是168，后面两个以此类推</span></span><br><span class="line">    output_data = interpreter.get_tensor(output_details[<span class="number">0</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data)  # 预测框的4个坐标值</span></span><br><span class="line">    output_data_1 = interpreter.get_tensor(output_details[<span class="number">1</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_1)  # 类别名称id</span></span><br><span class="line">    output_data_2 = interpreter.get_tensor(output_details[<span class="number">2</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_2)  # 置信度</span></span><br><span class="line">    output_data_3 = interpreter.get_tensor(output_details[<span class="number">3</span>][<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line">    <span class="comment"># print(output_data_3)  # 这个恒等于10，代表最大输出框个数，是在export_tflite_ssd_graph.py里面设置的</span></span><br><span class="line">    each_interpreter_time = time.time() - model_interpreter_start_time</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output_data_1[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(class_names[int(output_data_1[0][i])])</span></span><br><span class="line">        confidence_threshold = output_data_2[<span class="number">0</span>][i]</span><br><span class="line">        <span class="keyword">if</span> confidence_threshold &gt; <span class="number">0.3</span>:</span><br><span class="line">            <span class="comment"># 只绘制概率大于阈值的矩形框</span></span><br><span class="line">            label = <span class="string">&quot;&#123;&#125;: &#123;:.2f&#125;% &quot;</span>.<span class="built_in">format</span>(class_names[<span class="built_in">int</span>(output_data_1[<span class="number">0</span>][i])], output_data_2[<span class="number">0</span>][i] * <span class="number">100</span>)  <span class="comment"># label包含类别名称、置信度、单张图片推理时间</span></span><br><span class="line">            label2 = <span class="string">&quot;inference time : &#123;:.3f&#125;s&quot;</span> .<span class="built_in">format</span>(each_interpreter_time)</span><br><span class="line">            <span class="comment"># 注意output_data第一个和第二个[]里都是0，然后第三个[]不是按0到3的顺序</span></span><br><span class="line">            left_up_corner = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">1</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">0</span>]*original_image_height))</span><br><span class="line">            left_up_corner_higher = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">1</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">0</span>]*original_image_height)-<span class="number">20</span>)</span><br><span class="line">            right_down_corner = (<span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">3</span>]*original_image_width), <span class="built_in">int</span>(output_data[<span class="number">0</span>][i][<span class="number">2</span>]*original_image_height))</span><br><span class="line">            cv2.rectangle(frame_image, left_up_corner_higher, right_down_corner, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), thickness)</span><br><span class="line">            <span class="comment"># cv.rectangle()里的第2个第3个参数代表的是 左上角点的(x,y)，右下角点的(x,y)，不同于Rect rect(x, y, w, h);//左上坐标（x,y）和矩形的长(w)宽(h)</span></span><br><span class="line">            cv2.putText(frame_image, label, left_up_corner_higher, cv2.FONT_HERSHEY_DUPLEX, fontsize, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=thickness)</span><br><span class="line">            cv2.putText(frame_image, label2, (<span class="number">30</span>, <span class="number">30</span>), cv2.FONT_HERSHEY_DUPLEX, fontsize, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=thickness)</span><br><span class="line">    cv2.namedWindow(<span class="string">&#x27;detect_result&#x27;</span>, cv2.WINDOW_NORMAL)</span><br><span class="line">    <span class="comment"># cv2.resizeWindow(&#x27;detect_result&#x27;, 800, 600)</span></span><br><span class="line">    cv2.imshow(<span class="string">&quot;detect_result&quot;</span>, frame_image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use space to pause the video and use q to terminate the program</span></span><br><span class="line">    key = cv2.waitKey(<span class="number">10</span>) &amp; <span class="number">0xFF</span></span><br><span class="line">    <span class="keyword">if</span> key == <span class="built_in">ord</span>(<span class="string">&quot;q&quot;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> key == <span class="number">32</span>:</span><br><span class="line">        cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>实际测试时，我发现帧率非常地低，这是因为tensorflow lite的运算内核是专门为ARM处理器优化的，没有针对x86优化，所以在电脑上跑TFlite格式模型会很慢，这点StackOverflow上也有人提问：[<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/54093424/why-is-tensorflow-lite-slower-than-tensorflow-on-desktop">link</a>],但也有人发现了如果在电脑上跑float32位的tflite模型还更快一点[<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/58349690/tflite-quantized-inference-very-show">link</a>],我这边拿<a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz"><strong>ssdlite_mobilenet_v2_coco</strong></a>导出的tflite模型试了一下，果然是这样的，从它的名字可以看出来它是未量化的，虽然它的normalized_input_image_tensor要求输入是uint8位，但到后面的其他运算操作时还是会反量化（dequantize）为浮点数，这个从它的图结构可以看出来：<br><a target="_blank" rel="noopener" href="https://imgchr.com/i/t1aukR"><img src="https://s1.ax1x.com/2020/05/31/t1aukR.png" alt="t1aukR.png"></a></p>
<p>要把下载下来的ssdlite_mobilenet_v2_coco里的东西转换成tflite格式模型，这其中还有一些知识点。解压后我们倒是看到frozen_inference_graph.pb,没有看到tflite_graph.pb，那我们怎么生成ssdlite_mobilenet_v2_coco的tflite模型呢？<br><img src="https://s1.ax1x.com/2020/05/27/tEFR5n.png" alt="tEFR5n.png"></p>
<p>这时候我们要用到<strong>export_tflite_ssd_graph.py</strong>将文件夹里的<strong>model.ckpt</strong>先转化为tflite_graph.pb，然后再转化为tflite格式。我使用的命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tf1.13.1) D:\ChromeDownload\models-r1.13.0\research\object_detection&gt;python export_tflite_ssd_graph.py --pipeline_config_path samples&#x2F;configs&#x2F;ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix &quot;E:\Tensorflow_detection_model_zoo\ssdlite_mobilenet_v2_coco_2018_05_09\model.ckpt&quot; --output_directory exported_model</span><br></pre></td></tr></table></figure>
<p>注意，截止2020/5/9，<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/issues/8456">官方</a>说目前tensorflow OD API还只支持TF1.x，所以我是在tf1.13.1的环境、1.13版的models repo（因为我没有clone models 1.15的repo…）里执行这个命令行，否则会报错：No module named ‘tensorflow.tools.graph_transforms’，大家如果是1.15版的话也可以试试。</p>
<p>我建议大家都去看一看<strong>export_tflite_ssd_graph.py</strong>里面的源代码，里面有很多很重要的知识点，比如你可以在里面改检测时画面最多显示几个结果，以下是其部分内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">If add_postprocessing_op is true: frozen graph adds a</span><br><span class="line">  TFLite_Detection_PostProcess custom op node has four outputs:</span><br><span class="line">  detection_boxes: a float32 tensor of shape [1, num_boxes, 4] with box</span><br><span class="line">  locations</span><br><span class="line">  detection_classes: a float32 tensor of shape [1, num_boxes]</span><br><span class="line">  with class indices</span><br><span class="line">  detection_scores: a float32 tensor of shape [1, num_boxes]</span><br><span class="line">  with class scores</span><br><span class="line">  num_boxes: a float32 tensor of size 1 containing the number of detected boxes</span><br><span class="line">else:</span><br><span class="line">  the graph has two outputs:</span><br><span class="line">   &#39;raw_outputs&#x2F;box_encodings&#39;: a float32 tensor of shape [1, num_anchors, 4]</span><br><span class="line">    containing the encoded box predictions.</span><br><span class="line">   &#39;raw_outputs&#x2F;class_predictions&#39;: a float32 tensor of shape</span><br><span class="line">    [1, num_anchors, num_classes] containing the class scores for each anchor</span><br><span class="line">    after applying score conversion.</span><br><span class="line"></span><br><span class="line">Example Usage:</span><br><span class="line">--------------</span><br><span class="line">python object_detection&#x2F;export_tflite_ssd_graph \</span><br><span class="line">    --pipeline_config_path path&#x2F;to&#x2F;ssd_mobilenet.config \</span><br><span class="line">    --trained_checkpoint_prefix path&#x2F;to&#x2F;model.ckpt \</span><br><span class="line">    --output_directory path&#x2F;to&#x2F;exported_model_directory</span><br><span class="line"></span><br><span class="line">Config overrides (see the &#96;config_override&#96; flag) are text protobufs</span><br><span class="line">(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override</span><br><span class="line">certain fields in the provided pipeline_config_path.  These are useful for</span><br><span class="line">making small changes to the inference graph that differ from the training or</span><br><span class="line">eval config.</span><br><span class="line"></span><br><span class="line">Example Usage (in which we change the NMS iou_threshold to be 0.5 and</span><br><span class="line">NMS score_threshold to be 0.0):</span><br><span class="line">python object_detection&#x2F;export_tflite_ssd_graph \</span><br><span class="line">    --pipeline_config_path path&#x2F;to&#x2F;ssd_mobilenet.config \</span><br><span class="line">    --trained_checkpoint_prefix path&#x2F;to&#x2F;model.ckpt \</span><br><span class="line">    --output_directory path&#x2F;to&#x2F;exported_model_directory</span><br><span class="line">    --config_override &quot; \</span><br><span class="line">            model&#123; \</span><br><span class="line">            ssd&#123; \</span><br><span class="line">              post_processing &#123; \</span><br><span class="line">                batch_non_max_suppression &#123; \</span><br><span class="line">                        score_threshold: 0.0 \</span><br><span class="line">                        iou_threshold: 0.5 \</span><br><span class="line">                &#125; \</span><br><span class="line">             &#125; \</span><br><span class="line">          &#125; \</span><br><span class="line">       &#125; \</span><br><span class="line">       &quot;</span><br></pre></td></tr></table></figure>
<p>运行完上面的命令行之后，我们在exported_model目录下就有了tflite_graph.pb和tflite_graph.pbtxt。然后我们再把这个tflite_graph.pb的路径替换到前面<em>TFLiteConverter_uint8.py</em>里，run后就能导出<em>uint8_model_converted_from_exported_model.tflite</em>啦，这个就是ssdlite_mobilenet_v2_coco的tflite版，SSDLite的区别就是把SSD里面的传统卷积替换成深度可分离卷积。</p>
<p>紧接着用这个uint8_model_converted_from_exported_model.tflite放入<em>Test_TFLite_Model_With_Image_Folder.py</em>执行一下，执行后我发现，console打印出来的inference time竟然只有0.10~0.13s ！ 而前面3个模型的inference time都是0.4几秒！与它快速的推理速度相反的是，它的文件体积却有18,055 KB ! </p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>在tensorflow models的 object detection下面有两个用来导出pb格式文件的脚本：export_tflite_ssd_graph.py 和 export_inference_graph.py。两者的区别在于：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">export_tflite_ssd_graph</th>
<th style="text-align:center">export_inference_graph</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">导出的文件名</td>
<td style="text-align:center">tflite_graph.pb</td>
<td style="text-align:center">frozen_inference_graph.pb</td>
</tr>
<tr>
<td style="text-align:center">input_arrays</td>
<td style="text-align:center">[“normalized_input_image_tensor”]</td>
<td style="text-align:center">[“image_tensor”]</td>
</tr>
<tr>
<td style="text-align:center">output_arrays</td>
<td style="text-align:center">[‘TFLite_Detection_PostProcess’, ‘TFLite_Detection_PostProcess:1’, ‘TFLite_Detection_PostProcess:2’, ‘TFLite_Detection_PostProcess:3’]</td>
<td style="text-align:center">[“detection_boxes”, “detection_scores”, “detection_classes”, “num_detections”]</td>
</tr>
</tbody>
</table>
</div>
<h1 id="训练日记"><a href="#训练日记" class="headerlink" title="训练日记"></a>训练日记</h1><p><strong>2020/11/30</strong></p>
<p>备份链接：<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1S1W7Tq28y-lNcteAHoyNZ6jGx632g39m?usp=sharing">https://drive.google.com/drive/folders/1S1W7Tq28y-lNcteAHoyNZ6jGx632g39m?usp=sharing</a></p>
<p>问题：一个目标周围有多个矩形框</p>
<p>解决方案：减小<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/60bb50675ed7fab3afd05edab02a45acee57532a/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config#L130">batch_non_max_suppression</a> 里的 iou_threshold（从0.6到0.5）【<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/detection_postprocess.cc">TFLite后处理源代码</a>】</p>
<p><img src="https://gitee.com/wwdok/my-image-bed/raw/master/img/20201130221015.png" alt="image-20201130221015315"></p>
<p><strong>2020/12/1</strong></p>
<p>备份链接：<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1gFYxDIVEvmB7tmrqZ7ZDFVtfygsq3Zwy?usp=sharing">https://drive.google.com/drive/folders/1gFYxDIVEvmB7tmrqZ7ZDFVtfygsq3Zwy?usp=sharing</a></p>
<p>问题：1.误检多。把树叶、汽车都误检成目标。 2.矩形框回归效果差</p>
<p>解决方案：增加负样本，调整锚框的宽高比。</p>
<p><img src="https://gitee.com/wwdok/my-image-bed/raw/master/img/20201201224046.png" alt="image-20201201224046015"></p>
<h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><blockquote>
<p>我在github上的提问 : <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/issues/39688">https://github.com/tensorflow/tensorflow/issues/39688</a><br><br>tensorflow 各版本API : <a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf</a><br><br>TensorFlow Lite Object Detection Android Demo(含detect.tflite)：<a target="_blank" rel="noopener" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android">https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android</a></p>
</blockquote>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          Donate
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2020/05/22/%E6%8E%A2%E7%B4%A2Mobilenet%20SSD%E5%AE%B6%E6%97%8F%E7%9A%84TFLite/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2020/05/24/PaddleX%E5%88%9D%E4%BD%93%E9%AA%8C/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            PaddleX初体验
          
        </div>
      </a>
    
    
      <a href="/2020/04/18/%E5%9B%BE%E8%A7%A3YUV%E9%87%87%E6%A0%B7%E5%8E%9F%E7%90%86/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">图解YUV采样原理</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "Y8oqscHrnLuIwp1649iHgWjM-gzGzoHsz",
    app_key: "IjneyzqTD2fkFsPSEFKEW0lN",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "有什么想说的请在此留言~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2021
        <i class="ri-heart-fill heart_icon"></i> Wade Wang
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/yoga.png" alt="Hello World"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="http://wwdok.lofter.com">摄影</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯果汁吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>